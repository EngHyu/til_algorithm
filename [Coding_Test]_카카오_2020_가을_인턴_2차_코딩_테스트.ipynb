{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Coding Test] 카카오 2020 가을 인턴 2차 코딩 테스트.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN02JiayuwC4qfF53EGIvzE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EngHyu/til_algorithm/blob/master/%5BCoding_Test%5D_%EC%B9%B4%EC%B9%B4%EC%98%A4_2020_%EA%B0%80%EC%9D%84_%EC%9D%B8%ED%84%B4_2%EC%B0%A8_%EC%BD%94%EB%94%A9_%ED%85%8C%EC%8A%A4%ED%8A%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEFX-THnY3RL",
        "colab_type": "text"
      },
      "source": [
        "# 문제\n",
        "뉴스 검색 결과를 클러스터링하는 모듈을 제작한다고 가정한다.\n",
        "\n",
        "# 문서 벡터 생성\n",
        "문서 A, B의 유사도를 측정하기 위해 각 문서를 벡터로 표현한다. 문서에서 핵심 단어를 추출하여 각 문서에 포함된 단어의 tf-idf를 계산하여 활용한다.\n",
        "\n",
        "tf-idf: https://en.wikipedia.org/wiki/Tf-idf\n",
        "\n",
        "벡터의 크기는 테스트 케이스 내 모든 문서에 속한 고유 단어의 수와 같다. 각각의 차원은 해당 단어의 tf-idf score와 같다. 문서 벡터화를 Boolean Frequency를 예로 들어 설명해보자면, 전체 문서 속 고유 단어가 4개인 경우, 각 벡터 크기는 4가 되며, 각 차원의 값은 해당 단어가 문서에 들어있을 경우 1, 아닐 경우 0이 된다. tf-idf 계산 공식은 다음을 참고한다.\n",
        "\n",
        ">$tf(t, d) = 0.5 + 0.5 * \\frac{f_(t,d)}{max\\{f_{t',d}:t'{\\in}d\\}}$\n",
        "\n",
        ">$idf(t,D) = log\\frac{N}{|\\{d{\\in}D : t{\\in}d\\}|}$\n",
        "\n",
        "t = 단어, d = 문서, D = 전체 문서, $f_{t,d}$ = d에서 t의 개수를 의미한다. 로그는 밑이 자연상수(e)인 자연로그를 사용한다.\n",
        "\n",
        "# 문서 유사도\n",
        "두 벡터 간 유사도 계산을 나타내는 척도로 코사인 유사도를 사용한다.\n",
        "\n",
        "코사인 유사도: https://en.wikipedia.org/wiki/Cosine_similarity\n",
        "\n",
        "# 클러스터링\n",
        "문서 유사도를 측정했으면, 유사한 문서끼리 그룹화하여야 한다. 클러스터링은 문서를 처음 주어졌던 순서대로 순회하면서 다음 방법을 수행한다.\n",
        "1. 현재까지 생성된 클러스터 대표 문서 중 가장 유사한 문서를 찾고, 유사도 값이 0.98 이상이면 해당 클러스터에 포함한다. (여러 개의 클러스터가 이 조건을 만족하는 경우는 없다.)\n",
        "2. 1.의 조건을 만족하는 클러스터가 없으면 자신을 대표 문서로 하는 새로운 클러스터를 생성한다.\n",
        "3. 클러스터 배정이 완료되면 다음 문서로 넘어간다.\n",
        "\n",
        "# 입력 (input으로 받아야 함...)\n",
        "입력 첫 줄은 뉴스 정보의 수 N이 주어진다. 2번째 줄부터 뉴스 정보가 2줄에 걸쳐 입력된다. 각 뉴스 줄은\n",
        "\n",
        "  1. 뉴스 기사를 특정하는 Doc_ID와 핵심 단어의 개수 w\n",
        "  1. 공백으로 구분된 핵심 단어\n",
        "\n",
        "로 이루어진다.\n",
        "\n",
        "```\n",
        "7\n",
        "20200806203611754 8\n",
        "올림픽대로 강변북로 통제 서울 출근 지각 퇴근길 대란\n",
        "20200806003111043 6\n",
        "백종원 골목식당 창동 강정 예고\n",
        "20200806155137596 6\n",
        "아파트 전월세 월세 전세 보증금 급등\n",
        "20200805215334147 7\n",
        "올림픽대로 통제 강변북로 서울 퇴근길 대란 지각\n",
        "20200806093242998 6\n",
        "서울 올림픽대로 강변북로 지각 출근 대란\n",
        "20200805230051988 8\n",
        "갤럭시 버즈 라이브 공개 노이즈 캔슬링 품질 개선\n",
        "20200806140159987 5\n",
        "아파트 전월세 전세 월세 급등\n",
        "```\n",
        "\n",
        "# 제약조건\n",
        "```\n",
        "1 <= N <= 50\n",
        "Doc_ID = 17자리 정수\n",
        "1 <= w <= 100\n",
        "1 <= 각각의 단어 길이 <= 15\n",
        "단어는 공백으로 구분된다.\n",
        "```\n",
        "\n",
        "# 출력 (print)\n",
        "```\n",
        "4\n",
        "20200806203611754 3\n",
        "20200806003111043 1\n",
        "20200806155137596 2\n",
        "20200805230051988 1\n",
        "```\n",
        "\n",
        "# 참고로 클러스터링 된 문서는 다음과 같다.\n",
        "```\n",
        "(20200806203611754, 20200805215334147, 20200806093242998)\n",
        "(20200806003111043)\n",
        "(20200806155137596, 20200806140159987)\n",
        "(20200805230051988)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnGEDqYDRa-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  # code here..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m638K8wQlCW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from collections import Counter\n",
        "\n",
        "# doc_dict = {}\n",
        "# total_words = []\n",
        "\n",
        "# n = int(input())\n",
        "# for _ in range(n):\n",
        "#   doc_id, _ = input().split(\" \")\n",
        "#   words = input().split(\" \")\n",
        "#   total_words += words\n",
        "#   doc_dict[doc_id] = words\n",
        "\n",
        "# total_words = Counter(total_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bzaQcs9lADM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "n = 7\n",
        "total_words = Counter({'올림픽대로': 3, '강변북로': 3, '서울': 3, '지각': 3, '대란': 3, '통제': 2, '출근': 2, '퇴근길': 2, '아파트': 2, '전월세': 2, '월세': 2, '전세': 2, '급등': 2, '백종원': 1, '골목식당': 1, '창동': 1, '강정': 1, '예고': 1, '보증금': 1, '갤럭시': 1, '버즈': 1, '라이브': 1, '공개': 1, '노이즈': 1, '캔슬링': 1, '품질': 1, '개선': 1})\n",
        "doc_dict = {\n",
        "  '20200806203611754': ['올림픽대로', '강변북로', '통제', '서울', '출근', '지각', '퇴근길', '대란'],\n",
        "  '20200806003111043': ['백종원', '골목식당', '창동', '강정', '예고'],\n",
        "  '20200806155137596': ['아파트', '전월세', '월세', '전세', '보증금', '급등'],\n",
        "  '20200805215334147': ['올림픽대로', '통제', '강변북로', '서울', '퇴근길', '대란', '지각'],\n",
        "  '20200806093242998': ['서울', '올림픽대로', '강변북로', '지각', '출근', '대란'],\n",
        "  '20200805230051988': ['갤럭시', '버즈', '라이브', '공개', '노이즈', '캔슬링', '품질', '개선'],\n",
        "  '20200806140159987': ['아파트', '전월세', '전세', '월세', '급등']\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-Jn-p2LbgaY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "19ed280f-610f-498b-967f-d5392033cf74"
      },
      "source": [
        "from math import log, sqrt\n",
        "from functools import reduce\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# calculate tf-idf\n",
        "def tfidf(total_words, doc_dict):\n",
        "  tfidf_dict = defaultdict(list)\n",
        "  # for each word\n",
        "  for t, df in total_words.items():\n",
        "    # get idf(=Inverse Document Frequency)\n",
        "    idf = log(n / df)\n",
        "    # for each document\n",
        "    for doc_id, doc in doc_dict.items():\n",
        "      # get tf(=Term Frequency)\n",
        "      tf = 0.5 + 0.5 * (t in doc)\n",
        "      # tf-idf score = tf * idf\n",
        "      tfidf_dict[doc_id].append(tf * idf)\n",
        "\n",
        "  return tfidf_dict\n",
        "\n",
        "# cosine similarity\n",
        "def getSimilarity(v1, v2):\n",
        "  dot  = lambda v1, v2: sum([a*b for a, b in zip(v1, v2)])\n",
        "  norm = lambda vector: sqrt(sum([v*v for v in vector]))\n",
        "  return dot(v1, v2) / (normalize(v1) * normalize(v2))\n",
        "\n",
        "# clustering\n",
        "def clustering(tfidf_dict):\n",
        "  clusters = []\n",
        "  # for each document\n",
        "  for doc_id, tfidf in tfidf_dict.items():\n",
        "    # cosine similarity\n",
        "    similarity = 0\n",
        "    # for default document in clusters\n",
        "    for id, cluster in enumerate(clusters):\n",
        "      # get similarity\n",
        "      similarity = getSimilarity(tfidf, tfidf_dict[cluster[0]])\n",
        "      # if similar\n",
        "      if similarity >= 0.98:\n",
        "        clusters[id].append(doc_id)\n",
        "        break\n",
        "    # nothing similar\n",
        "    if similarity < 0.98:\n",
        "      clusters.append([doc_id])\n",
        "\n",
        "  return clusters\n",
        "\n",
        "# print answer\n",
        "def print_cluster(clusters):\n",
        "  print(len(clusters))\n",
        "  for cluster in clusters:\n",
        "    print(cluster[0], len(cluster))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  tfidf_dict = tfidf(total_words, doc_dict)\n",
        "  clusters = clustering(tfidf_dict)\n",
        "  print_cluster(clusters)\n",
        "  print(doc_dict, total_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "20200806203611754 3\n",
            "20200806003111043 1\n",
            "20200806155137596 2\n",
            "20200805230051988 1\n",
            "{'20200806203611754': ['올림픽대로', '강변북로', '통제', '서울', '출근', '지각', '퇴근길', '대란'], '20200806003111043': ['백종원', '골목식당', '창동', '강정', '예고'], '20200806155137596': ['아파트', '전월세', '월세', '전세', '보증금', '급등'], '20200805215334147': ['올림픽대로', '통제', '강변북로', '서울', '퇴근길', '대란', '지각'], '20200806093242998': ['서울', '올림픽대로', '강변북로', '지각', '출근', '대란'], '20200805230051988': ['갤럭시', '버즈', '라이브', '공개', '노이즈', '캔슬링', '품질', '개선'], '20200806140159987': ['아파트', '전월세', '전세', '월세', '급등']} Counter({'올림픽대로': 3, '강변북로': 3, '서울': 3, '지각': 3, '대란': 3, '통제': 2, '출근': 2, '퇴근길': 2, '아파트': 2, '전월세': 2, '월세': 2, '전세': 2, '급등': 2, '백종원': 1, '골목식당': 1, '창동': 1, '강정': 1, '예고': 1, '보증금': 1, '갤럭시': 1, '버즈': 1, '라이브': 1, '공개': 1, '노이즈': 1, '캔슬링': 1, '품질': 1, '개선': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2iw00TxS4u1",
        "colab_type": "text"
      },
      "source": [
        "# 문제 2\n",
        "MAB의 convergence time 측정하기\n",
        "\n",
        "# 문제\n",
        "AI 추천 플랫폼 토로스는 사용자 반응을 반영하여 추천 결과를 만들기 위해 멀티-암드 벤딧(Multi-Armed Bandit, MAB) 기술을 사용한다. MAB Problem은 서로 다른 보상확률을 가지는 슬롯머신(arm) 여러 대가 있을 때, 정해진 횟수만큼 슬롯머신을 시도하여 가장 많은 보상(reward)을 받을 수 있는 방법을 찾는 문제이다. 슬롯머신의 보상확률을 처음부터 알 수 있다면 가장 보상확률이 좋은 슬롯머신만 시도하여 이익을 최대화할 수 있지만, 슬롯머신의 보상확률을 모르는 상황에서는 직접 시도하면서 보상확률을 알아가는 동시에 보상을 축적해야 한다. 임의의 슬롯머신을 시도하며 보상확률을 유추하는 과정을 탐색(explore)이라고 부르며, 탐색 결과 보상확률이 가장 높은 슬롯머신을 시도하는 과정을 활용(exploit)이라고 부른다. 탐색을 많이 하면 보상확률이 높은 슬롯머신을 발견할 수 있는 대신 보상확률이 높은 슬로머신을 시도할 수 있는 횟수가 적어지고, 반면 탐색을 적게 하면 활용에 사용할 수 있는 횟수는 늘어나지만 각 슬롯머신에 대해 추정한 보상확률에 대한 정확도가 낮을 수 있다. 즉, 탐색과 활용의 순서와 비율을 잘 조정하며 이익을 최대화하는 것이 MAB Problem의 중요한 부분이다.\n",
        "\n",
        "슬롯머신을 콘텐츠로, 슬롯머신을 시도하는 행위는 콘텐츠를 추천 결과로 노출(impression)하는 행위로, 슬롯머신의 보상은 사용자가 콘텐츠를 클릭(click)했는지 여부로, 슬롯머신의 보상확률은 콘텐츠에 대한 사용자의 클릭률로 바라보면, 가장 높은 클릭률(추천을 통해 노출된 콘텐츠 중 사용자가 클릭한 콘텐츠의 비율)을 달성할 콘텐츠를 추천하는 문제를 MAB Problem으로 볼 수 있다. 이 MAB Problem의 목표는 사용자가 클릭할 확률이 높은 콘텐츠를 추천 결과로 노출하여 클릭률을 최대화하는 것이다. 클릭률은 추천 로직의 성능을 판단하는 지표로 사용되며, 클릭률이 높을수록 추천 로직의 성능이 높다고 판단한다. 그리고 각 콘텐츠의 클릭률을 알기 위해서는 사용자에게 콘텐츠를 노출하고 사용자의 반응에 따른 보상을 측정한 후 탐색과 활용을 조정하며 다음 추천 결과를 결정해야 한다.\n",
        "\n",
        "토로스는 MAB Problem을 해결하기 위한 방법론 중 톰슨 샘플링(Thompson Sampling) 알고리즘을 사용한다. 톰슨 샘플링은 탐색 결과로 각 슬롯머신의 보상을 분포로 추정하여, 추정한 보상이 높은 슬롯머신일수록 높은 확률로 선택(draw)하는 알고리즘이다. 톰슨 샘플링에서 슬롯머신의 보상은 베르누이 시행을 따라 0 또는 1의 값을 가지며, 슬롯머신의 보상 확률 P는 각 슬롯머신의 보상 이력을 반영한 베타 분포(Beta Distribution)를 따른다고 가정한다. 베타 분포는 두 가지 파라미터(A, B)에 의해 [0, 1] 구간에서 정의되는 연속확률 분포이며, Beta(A, B)는 일반적으로 A 값이 크면 1에 가까울 확률이 높아지고 B 값이 크면 0에 가까운 확률이 높은 분포이다.\n",
        "\n",
        "이러한 톰슨 샘플링 알고리즘에서는 탐색의 결과가 쌓여감에 따라 각 슬롯머신의 추정된 보상확률이 수렴하게 된다. 알고리즘이 시작된 초반에는 시도 횟수가 적기 때문에 각 슬롯머신의 보상확률이 큰 변화폭을 가지지만, 점차 누적 시도 횟수가 증가하면서 각 슬롯머신의 보상 데이터는 특정 보상확률에 수렴하는 분포를 따르게 되는 것이다. 이 때 MAB 알고리즘이 수렴하는 시점은 클릭률이 일정한 값으로 수렴되는 시점과 동일하며, 클릭률의 변화를 측정하는 방법뿐 아니라 슬롯머신의 분산값들을 이용해서도 MAB 알고리즘의 수렴 여부를 판단할 수 있다.\n",
        "\n",
        "**Algorithm 2 Tompson sampling for the Bernoulli bandit**\n",
        "\n",
        "**Require:** $\\alpha, \\beta$ prior parameters of a Beta distribution\n",
        "\n",
        "$S_i = 0, F_i=0, {\\forall}i.${Success and failure counters}\n",
        "\n",
        "$for$ $t$ = 1, ..., $T$ $do$\n",
        "\n",
        ">$for$ $i$ = 1, ..., $K$ $do$\n",
        ">>Draw $\\theta_i$ according to $Beta(S_i+\\alpha,F_i+ \\beta)$\n",
        "\n",
        ">$end$ $for$\n",
        "\n",
        ">Draw arm $i$ = arg $max_i$ $\\theta_i$ and observe reward $r$\n",
        "\n",
        ">$if$ $r$ = 1 $then$\n",
        ">>$S_i=S_i+1$\n",
        "\n",
        ">$else$\n",
        ">>$F_i=F_i+1$\n",
        "\n",
        ">$end if$\n",
        "\n",
        "$end for$\n",
        "\n",
        "추천팀에 입사한 뿌요는 새롭게 런칭한 카카오의 서비스에 톰슨 샘플링 MAB 알고리즘을 적용하게 되었다. 톰슨 샘플링 MAB 알고리즘을 적용하려던 부요는 위 슈도 코드에서 문제점들을 발견했다. 추천 결과에 대한 보상 여부를 확인하는 데에 사용하는 피드백 데이터(통계 데이터)는 추천 결과로 콘텐츠가 노출되었다는 정보와 노출된 콘텐츠가 클릭되었다는 정보로 이루어져 있어서, 노출된 콘텐츠가 클릭된 경우에는 피드백 데이터가 일정 시간이 지나 불규칙한 시점에 들어온다. 이 때문에 슈도 코드처럼 **추천 결과 생성**과 **보상 여부 확인**과 ((베타 분포의 파라미터를 업데이터** 하는 세 과정을 동시에 수행할 수 없다. 그래서 뿌요는 각 과정을 독립적으로 수행하도록 슈도 코드를 변형했다. 예를 들어, 콘텐츠 X를 나타내는 슬롯머신의 보상확률 P가 $Beta(\\alpha,\\beta)$의 prior distribution을 따를 때 콘텐츠 X가 사용자에게 추천 결과로 5번 노출되어 사용자가 3번 클릭하는 사건이 발생했다고 하자. 이 때 사용자의 클릭 여부에 의해 콘텐츠 X를 나타내는 슬롯머신의 보상확률을 갱신할 수 있으며, 이 슬롯머신의 posterior distribution은 $Beta(\\alpha+3,\\beta+5-3)$로 추정한다.\n",
        "\n",
        "뿌요가 구현한 MAB 알고리즘은 추천 결과에 대한 피드백 데이터가 일정 수준 이상 쌓이고 나서 NAB 알고리즘이 수렴한 이후에 제 성능을 알 수 있기 때문에, 여러 추천 로직의 성능 비교를 위해서는 각 추천 로직에 적용된 MAB 알고리즘의 수렴 여부를 판단하는 것이 중요하다. MAB 알고리즘을 구현하느라 에너지를 다 쓴 뿌요는 톰슨 샘플링 MAB 알고리즘을 추천 시스템에 적용한 후 허니요거베리를 먹으러 카카오 카페에 다녀오려고 한다. 허니요거베리를 먹으러 카페에 다녀오기 위해 MAB 알고리즘이 수렴하는 데에 걸리는 시간이 궁금했던 뿌요는 마침 이전 실험 기록들을 발견했다. 이전 실험 기록들을 참고하여 대략적인 수렴 시간을 알 수 있다면 뿌요가 마음 편히 허니요거베리를 먹으러 카페에 다녀올 수 있을 것이다. 뿌요의 간식 타임을 위해, 실험 데이터가 주어졌을 때 해당 MAB 알고리즘이 수렴하는 데에 걸리는 시간을 측정해주자.\n",
        "\n",
        "MAB 알고리즘의 수렴 여부를 판단하는 여러 방법 중 뿌요가 실험 기록으로 수렴 시간을 추정한 방법은 다음과 같다. (N: 총 피드백 데이터 수, 1 <= k <= N)\n",
        "\n",
        "1. 각 슬롯머신의 초기 prior distribution은 $\\alpha$ = 1.0, $\\beta$ = 15.0인 베타 분포로 가정한다.\n",
        "1. 슬롯머신은 **베타 분포를 따르며** 슬롯머신의 보상확률은 **피드백이 들어올 때마다 갱신**된다.\n",
        "1. $S_k$ : k번째 피드백이 입력으로 들어왔을 때, **k번째 피드백까지 등장한 슬롯머신들의 분산의 평균**에 **자연로그(ln) 스케일**을 적용한 값\n",
        "1. $max_S$ : $S_1$\\~$S_N$의 최댓값, $min_S$ : $S_1$\\~$S_N$의 최솟값\n",
        "1. $(S_k - min_S) <= (max_S - min_S) * 0.05$가 되는 첫 시점을 MAB 알고리즘이 수렴했다고 판단한다.\n",
        "\n",
        "# 채점\n",
        "각 테스트 케이스의 |정답*출력|의 총합이 error로 표기됩니다.\n",
        "score는 error가 작을수록 높은 값을 나타내며, 95 이상일 때 PASS로 채점됩니다.\n",
        "\n",
        "c++ / java의 경우 계산하는 순서에 따라 overflow가 일어날 수 있어 계산할 때 overflow가 일어나지 않도록 주의해야 합니다.\n",
        "\n",
        "python의 경우 구현에 따라 시간 초과가 발생할 수 있어 시간복잡도를 고려한 구현이 필요합니다.\n",
        "\n",
        "# 입력\n",
        "첫 번째 줄에 테스트 케이스 개수 T(1 <= T <= 10)가 입력으로 주어집니다. 두 번째 줄부터 테스트 케이스가 시작됩니다.\n",
        "\n",
        "각 테스트 케이스의 첫 번째 줄에 N(100 <= N <= 100000)이 주어집니다. 그 다음의 1~N번째의 줄에는 한 줄에 피드백 데이터 하나씩, 총 피드백 데이터 N개가 주어집니다.\n",
        "\n",
        "각 피드백 데이터는 공백을 기준으로 item id(콘텐츠 ID), 노출을 의미하는 'imp' 또는 클릭을 의미하는 'click', 노출 횟수 또는 클릭 횟수를 나타냅니다.\n",
        "\n",
        "(item id와 횟수는 0 이상 2147438647 이하의 정수입니다.)\n",
        "\n",
        "예시:\n",
        "```\n",
        "2\n",
        "9\n",
        "102 imp 7\n",
        "23 imp 23\n",
        "23 click 2\n",
        "41 imp 23\n",
        "50 imp 75\n",
        "41 imp 23\n",
        "41 click 5\n",
        "23 imp 2\n",
        "102 click 3\n",
        "8\n",
        "102 imp 15\n",
        "41 imp 23\n",
        "50 imp 75\n",
        "23 imp 23\n",
        "23 click 2\n",
        "41 imp 23\n",
        "41 click 5\n",
        "23 imp 2\n",
        "```\n",
        "\n",
        "# 출력\n",
        "각 테스트 케이스마다 수렴 시점으로 추정되는 피드백 데이터의 인덱스를 한 줄에 하나씩 출력합니다.\n",
        "\n",
        "(피드백 데이터의 인덱스는 1부터 시작합니다.)\n",
        "\n",
        "예시:\n",
        "```\n",
        "6\n",
        "3\n",
        "```\n",
        "\n",
        "예시 출력 첫 줄의 6은 첫 번째 테스트 케이스에서는 입력 피드백 데이터 중 인덱스 6(\"41 imp 23\")에서 수렴되었다는 것을 의미합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L2PbWeegdIV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e798a824-b4d0-467f-af92-0f7b5adc0555"
      },
      "source": [
        "input = [\"2\",\n",
        "\"9\",\n",
        "\"102 imp 7\",\n",
        "\"23 imp 23\",\n",
        "\"23 click 2\",\n",
        "\"41 imp 23\",\n",
        "\"50 imp 75\",\n",
        "\"41 imp 23\",\n",
        "\"41 click 5\",\n",
        "\"23 imp 2\",\n",
        "\"102 click 3\",\n",
        "\"8\",\n",
        "\"102 imp 15\",\n",
        "\"41 imp 23\",\n",
        "\"50 imp 75\",\n",
        "\"23 imp 23\",\n",
        "\"23 click 2\",\n",
        "\"41 imp 23\",\n",
        "\"41 click 5\",\n",
        "\"23 imp 2\"]\n",
        "\n",
        "from math import log, sqrt\n",
        "from functools import reduce\n",
        "from collections import defaultdict\n",
        "\n",
        "INITIAL = log(15 / (16 ** 3))\n",
        "\n",
        "def update(content, isImp, cnt):\n",
        "  if isImp:\n",
        "    content = [1, 15 + cnt, 0]\n",
        "\n",
        "  else:\n",
        "    content[0] += cnt\n",
        "    content[1] -= cnt\n",
        "\n",
        "  a, b, _ = content\n",
        "  content[2] = (a * b) / ((a + b) ** 2 * (a + b + 1))\n",
        "  return content\n",
        "\n",
        "def MAB():\n",
        "  contents_len = 0\n",
        "  contents = defaultdict(list)\n",
        "\n",
        "  S = []; min_S = INITIAL; max_S = INITIAL \n",
        "  N = int(input.pop(0))\n",
        "  # N = int(input())\n",
        "  \n",
        "  for idx in range(N):\n",
        "    # id, isImp, cnt = input().split()\n",
        "    id, isImp, cnt = input.pop(0).split()\n",
        "    isImp = isImp == 'imp'\n",
        "    cnt = int(cnt)\n",
        "\n",
        "    if contents[id] == []:\n",
        "      contents_len += 1\n",
        "    contents[id] = update(contents[id], isImp, cnt)\n",
        "    \n",
        "    S_k = log(reduce(lambda acc,ele: acc+ele[2], contents.values(), 0) / contents_len)\n",
        "    if S_k < min_S:\n",
        "      min_S = S_k\n",
        "    if S_k > max_S:\n",
        "      max_S = S_k\n",
        "    # S.append(S_k)\n",
        "\n",
        "    if idx == 0:\n",
        "      continue\n",
        "\n",
        "    print(min_S, INITIAL, S_k - min_S, 0.05 * (max_S - min_S))\n",
        "    if S_k - min_S <= 0.05 * (max_S - min_S):\n",
        "      print(idx)\n",
        "      break\n",
        "  \n",
        "  for _ in range(N-idx-1):\n",
        "    input.pop(0)\n",
        "\n",
        "T = int(input.pop(0))\n",
        "for _ in range(T):\n",
        "  MAB()\n",
        "\n",
        "# 각 슬롯머신의 초기 prior distribution은  𝛼  = 1.0,  𝛽  = 15.0인 베타 분포로 가정한다.\n",
        "# 슬롯머신은 베타 분포를 따르며 슬롯머신의 보상확률은 피드백이 들어올 때마다 갱신된다.\n",
        "# 𝑆𝑘  : k번째 피드백이 입력으로 들어왔을 때, k번째 피드백까지 등장한 슬롯머신들의 분산의 평균에 자연로그(ln) 스케일을 적용한 값\n",
        "# 𝑚𝑎𝑥𝑆  :  𝑆1 ~ 𝑆𝑁 의 최댓값,  𝑚𝑖𝑛𝑆  :  𝑆1 ~ 𝑆𝑁 의 최솟값\n",
        "# (𝑆𝑘−𝑚𝑖𝑛𝑆)<=(𝑚𝑎𝑥𝑆−𝑚𝑖𝑛𝑆)∗0.05 가 되는 첫 시점을 MAB 알고리즘이 수렴했다고 판단한다.\n",
        "# (𝑆𝑘−𝑚𝑖𝑛𝑆)<=(𝑚𝑎𝑥𝑆−𝑚𝑖𝑛𝑆)∗0.05"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-6.743335369926342 -5.609715965617133 0.0 0.05668097021546044\n",
            "1\n",
            "-7.130814213839627 -5.609715965617133 0.0 0.07605491241112468\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5nRt4_NVgcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}